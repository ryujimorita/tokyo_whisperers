@misc{huggingfaceReazonspeechDatasets,
	author = {Reazon Human Interaction Lab},
	title = {ReazonSpeech - Datasets at Hugging Face},
	url = {https://huggingface.co/datasets/reazon-research/reazonspeech},
	year = {},
}

@misc{reazon20240801ReazonSpeech,
	author = {Reazon Human Interaction Lab},
	title = {(2024-08-01) ReazonSpeech blog: Setting a New Standard in Japanese},
	url = {https://research.reazon.jp/blog/2024-08-01-ReazonSpeech.html},
	year = {},
}

@misc{hu2021loralowrankadaptationlarge,
      title={LoRA: Low-Rank Adaptation of Large Language Models}, 
      author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
      year={2021},
      eprint={2106.09685},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2106.09685}, 
}

@misc{xu2023parameterefficientfinetuningmethodspretrained,
      title={Parameter-Efficient Fine-Tuning Methods for Pretrained Language Models: A Critical Review and Assessment}, 
      author={Lingling Xu and Haoran Xie and Si-Zhao Joe Qin and Xiaohui Tao and Fu Lee Wang},
      year={2023},
      eprint={2312.12148},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2312.12148}, 
}

@misc{githubWhispermodelcardmdMain,
	author = {openai},
	title = {whisper/model-card.md},
	url = {https://github.com/openai/whisper/blob/main/model-card.md},
	year = {2024},
}

@inproceedings{radford2023robust,
  title={Robust speech recognition via large-scale weak supervision},
  author={Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  booktitle={International conference on machine learning},
  pages={28492--28518},
  year={2023},
  organization={PMLR}
}

@misc{githubOpenaiWhisper,
	author = {},
	title = {GitHub - openai/whisper},
	url = {https://github.com/openai/whisper?tab=readme-ov-file#available-models-and-languages},
	year = {},
}

@misc{githubReazonSpeech,
	author = {},
	title = {Massive open Japanese speech corpus},
	url = {https://github.com/reazon-research/ReazonSpeech?tab=readme-ov-file#packages},
	year = {},
	note = {[Accessed 09-12-2024]},
}

@misc{ardilaCommonVoiceMassivelyMultilingual2020,
  title = {Common {{Voice}}: {{A Massively-Multilingual Speech Corpus}}},
  author = {Ardila, Rosana and Branson, Megan and Davis, Kelly and Henretty, Michael and Kohler, Michael and Meyer, Josh and Morais, Reuben and Saunders, Lindsay and Tyers, Francis M. and Weber, Gregor},
  year = {2020},
  eprint = {1912.06670},
  archivePrefix = {arXiv},
  primaryClass = {cs},
  url = {http://arxiv.org/abs/1912.06670}
}

@misc{conneauFLEURSFewshotLearning2022,
  title = {{{FLEURS}}: {{Few-shot Learning Evaluation}} of {{Universal Representations}} of {{Speech}}},
  author = {Conneau, Alexis and Ma, Min and Khanuja, Simran and Zhang, Yu and Axelrod, Vera and Dalmia, Siddharth and Riesa, Jason and Rivera, Clara and Bapna, Ankur},
  year = {2022},
  eprint = {2205.12446},
  archivePrefix = {arXiv},
  primaryClass = {cs},
  url = {http://arxiv.org/abs/2205.12446}
}

@misc{huLoRALowRankAdaptation2021,
  title = {{{LoRA}}: {{Low-Rank Adaptation}} of {{Large Language Models}}},
  author = {Hu, Edward J. and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  year = {2021},
  eprint = {2106.09685},
  archivePrefix = {arXiv},
  primaryClass = {cs},
  url = {http://arxiv.org/abs/2106.09685}
}

@misc{holdingsReazonSpeechV21Setting2024,
  title = {ReazonSpeech v2.1: Setting a New Standard in Japanese ASR},
  author = {Yin, Yue and Mori, Daijiro and Fujimoto, Seiji},
  year = {2024},
  url = {https://research.reazon.jp/blog/2024-08-01-ReazonSpeech.html}
}

@misc{radfordRobustSpeechRecognition,
      title={Robust Speech Recognition via Large-Scale Weak Supervision}, 
      author={Alec Radford and Jong Wook Kim and Tao Xu and Greg Brockman and Christine McLeavey and Ilya Sutskever},
      year={2022},
      eprint={2212.04356},
      archivePrefix={arXiv},
      primaryClass={eess.AS},
      url={https://arxiv.org/abs/2212.04356}, 
}

@misc{sonobeJSUTCorpusFree2017,
  title = {{{JSUT}} Corpus: Free Large-Scale {{Japanese}} Speech Corpus for End-to-End Speech Synthesis},
  author = {Sonobe, Ryosuke and Takamichi, Shinnosuke and Saruwatari, Hiroshi},
  year = {2017},
  eprint = {1711.00354},
  archivePrefix = {arXiv},
  primaryClass = {cs},
  url = {http://arxiv.org/abs/1711.00354}
}

@misc{yinReazonSpeechFreeMassive,
  title = {{{ReazonSpeech}}: {{A Free}} and {{Massive Corpus}} for {{Japanese ASR}}},
  author = {Yin, Yue and Mori, Daijiro and Fujimoto, Seiji},
  abstract = {ReazonSpeech is a 15,000-hour and continuously growing corpus collected from Japanese TV shows free for commercial usage. The automatic speech recognition (ASR) model trained on ReazonSpeech achieves state-of-the-art results with 8.23\% character error rate (CER) on JSUT basic5000[1] and 9.93\% on Common Voice[2] v8.0 test set, on par with the recently released Whisper[3] largev2 model. We released the dataset creation toolkit under Apache License 2.0 and made both the corpus and the pretrained ASR model freely available1ï¼‰.},
  langid = {english},
  year = {2023}
}

@inproceedings{karitaLenientEvaluationJapanese2023,
  title = {Lenient {{Evaluation}} of {{Japanese Speech Recognition}}: {{Modeling Naturally Occurring Spelling Inconsistency}}},
  shorttitle = {Lenient {{Evaluation}} of {{Japanese Speech Recognition}}},
  booktitle = {Proceedings of the {{Workshop}} on {{Computation}} and {{Written Language}} ({{CAWL}} 2023)},
  author = {Karita, Shigeki and Sproat, Richard and Ishikawa, Haruko},
  year = {2023},
  pages = {61--70},
  publisher = {Association for Computational Linguistics},
  location = {Toronto, Canada},
  doi = {10.18653/v1/2023.cawl-1.8},
  url = {https://aclanthology.org/2023.cawl-1.8},
  urldate = {2024-12-08},
  abstract = {Word error rate (WER) and character error rate (CER) are standard metrics in Speech Recognition (ASR), but one problem has always been alternative spellings: If one's system transcribes adviser whereas the ground truth has advisor, this will count as an error even though the two spellings really represent the same word.},
  eventtitle = {Proceedings of the {{Workshop}} on {{Computation}} and {{Written Language}} ({{CAWL}} 2023)},
  langid = {english}
}

@misc{IndroducingWhisper,
  author = {OpenAI},
  title = {Introducing Whisper},
  howpublished = {GitHub Repository},
  url = {https://openai.com/index/whisper/},
  year = {2022}
}

@misc{MediumWhisper,
  howpublished = {Medium},
  author = {David Cochard},
  title = {Whisper: Speech Recognition Model Capable of Recognizing 99 Languages},
  url = {https://medium.com/axinc-ai/whisper-speech-recognition-model-capable-of-recognizing-99-languages-5b5cf0197c16},
  year = {2023}
}

@misc{ReazonSpeechNemo,
  author = {Reazon Human Interaction Lab},
  title = {ReazonSpeechNemo Hugging Face Repository},
  howpublished = {Hugging Face Repository},
  url = {https://huggingface.co/reazon-research/reazonspeech-nemo-v2}
}

@misc{ReazonSpeechK2,
  author = {Reazon Human Interaction Lab},
  title = {ReazonSpeechK2 Hugging Face Repository},
  howpublished = {Hugging Face Repository},
  url = {https://huggingface.co/reazon-research/reazonspeech-k2-v2}
}

@misc{ReazonSpeechESPNet,
  author = {Reazon Human Interaction Lab},
  title = {ReazonSpeechESPNet Hugging Face Repository},
  howpublished = {Hugging Face Repository},
  url = {https://huggingface.co/reazon-research/reazonspeech-espnet-v2}
}

@misc{Icefall,
  author = {The Icefall Project Contributors},
  title = {Icefall Project Repository},
  howpublished = {GitHub Repository},
  url = {https://github.com/k2-fsa/icefall},
}

@article{SpecAugment,
  title={SpecAugment: A simple data augmentation method for automatic speech recognition},
  author={Park, Daniel S and Chan, William and Zhang, Yu and Chiu, Chung-Cheng and Zoph, Barret and Cubuk, Ekin D and Le, Quoc V},
  journal={arXiv preprint arXiv:1904.08779},
  year={2019}
}

